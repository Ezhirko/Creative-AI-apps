# ğŸš€ SmolLM2 LLM Deployment in Docker ğŸ³  

This repository demonstrates how to **deploy a 135M parameter SmolLM2 Large Language Model (LLM) in a Docker container** and set up another container to interact with it. Using **FastAPI**, we serve the model in one container while another container sends API requests, fetches the results, and displays them.

---

## ğŸ“Œ Features  

âœ… **Containerized SmolLM2 LLM** using Docker  
âœ… **FastAPI-based API** for text generation  
âœ… **Multi-container communication** using Docker Compose  
âœ… **Real-time inference across containers**  
âœ… **Step-by-step deployment guide**  

---

## ğŸ“‚ Project Structure  
```bash
â”œâ”€â”€ ğŸ“‚ SmolLM2Server # Container 1: Hosting the LLM API
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ main.py # FastAPI server to serve LLM
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â”œâ”€â”€ model/ # Folder for storing the SmolLM2 model
â”‚ â”œâ”€â”€ config.yaml
â”‚ â””â”€â”€ ...
â”œâ”€â”€ ğŸ“‚ TextGenerator # Container 2: Sending API requests
â”‚ â”œâ”€â”€ Dockerfile
â”‚ â”œâ”€â”€ main.py # FastAPI server to fetch results
â”‚ â”œâ”€â”€ templates/ # HTML files for frontend
â”‚ â”œâ”€â”€ requirements.txt
â”‚ â””â”€â”€ ...
â”œâ”€â”€ docker-compose.yml # Defines services and networking
â””â”€â”€ README.md # Project documentation
```

---

## ğŸš€ Setup & Installation  

### ğŸ”¹ Prerequisites  
Ensure you have the following installed on your system:  
- ğŸ³ **Docker**  
- ğŸ **Python 3.8+**  
- ğŸ“¦ **pip & virtualenv**  

---

### ğŸ”¹ Step 1: Clone the Repository  

```bash
git clone https://github.com/Ezhirko/Creative-AI-apps.git
cd Creative-AI-apps
```

### ğŸ”¹ Step 2: Build & Run Docker Containers
```bash
 docker-compose up --build
```

This will:<br>
âœ… **Build** the SmolLM2 model API container (app1) <br>
âœ… **Build** the Text Generator container (app2) <br>
âœ… **Start** both containers and link them using a Docker network <br>

### ğŸ”¹ Step 3: Access the Application
Once both containers are up and running:

- SmolLM2 API (Container 1) â†’ http://localhost:8001
- Text Generator (Container 2) â†’ http://localhost:8000
  
ğŸ“¢ Open http://localhost:8000 in your browser and interact with the LLM!

---
### ğŸ“Œ API Endpoints
ğŸ”¹ SmolLM2 API (Container 1)
| Method | Endpoint | Description                |
|--------|----------|----------------------------|
| POST   | /generate| Generates text from prompt |

ğŸ”¹ Text Generator API (Container 2)
| Method | Endpoint | Description                      |
|--------|----------|----------------------------------|
| GET    | /        | UI to enter prompt & view output |
| POST   | /generate| Sends prompt to SmolLM2 API      |

### ğŸ“º Video Demonstration
ğŸ¥ Watch the full deployment and setup guide here:
ğŸ”— [YouTube Video Link](https://youtu.be/56EwkD_KcUA)



