{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tamil Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from BEPTokenizer import BEPTokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Read the Tamil dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File content read successfully.\n",
      "<doc id=\"3\" url=\"https://ta.wikipedia.org/wiki?curid=3\" title=\"முதற் பக்கம்\">\n",
      "முதற் பக்கம்\n",
      "\n",
      "\n",
      "\n",
      "</doc>\n"
     ]
    }
   ],
   "source": [
    "# Define the file path\n",
    "file_path = \"data/tamil_article_corpus.txt\"\n",
    "\n",
    "# Open and read the file\n",
    "try:\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        content = file.read()\n",
    "        print(\"File content read successfully.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file at {file_path} was not found.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred while reading the file: {e}\")\n",
    "\n",
    "# Print the first 100 characters for verification (optional)\n",
    "print(content[:100])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Start the BPE Tokenizer training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before training: tokens length: 1048108\n",
      "Training started...\n",
      "Training completed successfully!\n",
      "After training: tokens length: 91335\n",
      "After training: merges length: 4744\n",
      "After Training Vocab length 5000\n",
      "compression ratio: 11.48X\n"
     ]
    }
   ],
   "source": [
    "max_vocab_size = 5000\n",
    "tamil_tokenizer = BEPTokenizer(content,max_vocab_size)\n",
    "vocab, merges = tamil_tokenizer.train_BPE_Tokenizer()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encode the Sample Tamil text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1616, 341, 379, 384, 329, 340, 884, 294, 535, 720, 323, 327, 395, 1268, 1571, 331, 271, 46]\n"
     ]
    }
   ],
   "source": [
    "inp_string = \"உங்கள் மெர்சிடிஸ் பென்ஸ் கார் அழகாக இருக்கிறத.\"\n",
    "code = tamil_tokenizer.encode(inp_string)\n",
    "print(code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Decode the encoded value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'உங்கள் மெர்சிடிஸ் பென்ஸ் கார் அழகாக இருக்கிறத.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tamil_tokenizer.decode(code)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
